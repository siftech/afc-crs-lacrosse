#!/usr/bin/env bash

# This accepts a ctask id and a list of Azure SAS urls to download ctask source code

set -e
DEBUG=1

thisdir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && cd -P "$( dirname "$SOURCE" )" && /bin/pwd )"

PROGNAME=$(basename "$0")
warn()  { echo "$PROGNAME: ${@}" 1>&2; }
die()   { warn "${@}"; exit 1; }
dbug()   { test -z $DEBUG || warn "${@}"; }

# Run in container or on host
CRS_API_USER=${HOST_USERNAME:-$USER}
dbug CRS_API_USER is $CRS_API_USER

CIRCA_BASEPORT=${CIRCA_BASEPORT:-10000}
dbug CIRCA_BASEPORT is $CIRCA_BASEPORT

CP_ROOT=${AIXCC_CP_ROOT:-"/cp_root"}
dbug "CP_ROOT is $CP_ROOT"
TASK_ID=$1

if [ "$#" -lt 2 ]; then
  die "Expecting <task_id> <tar_sas_token_url_1> <tar_sas_token_url_2> ..."
fi

dbug "TASK_ID is $TASK_ID"

# Parse out the (optional) deadline arg
DEADLINE_MS=""
POSITIONAL=()

while [[ $# -gt 0 ]]; do
    case "$1" in
	--deadline)
	    DEADLINE_MS="$2"
	    shift 2
	    ;;
	--*)
	    echo "Unknown option: $1"
	    exit 1
	    ;;
	*)  # Not a flag: treat as positional argument
	    POSITIONAL+=("$1")
	    shift
	    ;;
    esac
done

# Restore positional arguments
set -- "${POSITIONAL[@]}"

# This needs testing
if [ -d "${CP_ROOT}/${TASK_ID}" ] && [ -z "$(ls -A ${CP_ROOT}/${TASK_ID})" ]; then
  warn "$TASK_ID directory already exits at ${CP_ROOT}/${TASK_ID} and is not empty!"
  warn "Exitting with 0."
  exit 0
fi

mkdir -p "${CP_ROOT}/${TASK_ID}"
# pushd ${CP_ROOT}
# mkdir -p ${TASK_ID}
# popd

# Converts seconds to HH:MM:SS format
format_hms() {
  local total_seconds=$1
  printf "%02d:%02d:%02d" $((total_seconds / 3600)) $(( (total_seconds % 3600) / 60 )) $(( total_seconds % 60 ))
}

# Compute max_total_seconds based on DEADLINE_MS if provided
if [[ -n "$DEADLINE_MS" && "$DEADLINE_MS" =~ ^[0-9]+$ ]]; then
  # Convert ms to seconds
  now_sec=$(date +%s)
  deadline_sec=$(( DEADLINE_MS / 1000 ))
  max_total_seconds=$(( deadline_sec - now_sec ))
  if (( max_total_seconds <= 0 )); then
    echo "Deadline is too soon or already passed â€” skipping downloads."
    continue
  fi
else
  # Default to 3.75 hours
  max_total_seconds=$((3 * 3600 + 2700))
fi

echo "Time until deadline: $(format_hms $max_total_seconds)"

warn "Getting source for task: ${TASK_ID}..."

echo "args before shift: $@"
shift
echo "args after shift: $@"

initial_sleep=2
max_sleep=60  # max 1 minute between rounds of attempts
start_time=$(date +%s)

for sas_token_url in "$@"; do
  echo
  echo
  echo
  echo "Attempting to download sas_token_url $sas_token_url..."
  sleep_time=$initial_sleep
  while true; do
    echo
    echo
    now=$(date +%s)
    elapsed=$((now - start_time))
    remaining=$((max_total_seconds - elapsed))

    echo "Elapsed time: $(format_hms $elapsed), Remaining time: $(format_hms $remaining)"
    
    if (( elapsed >= max_total_seconds )); then
      echo "Download utterly failed after $(format_hms $elapsed) for $sas_token_url"
      break
    fi

    if [[ "$sas_token_url" == *"blob.core.windows"* ]]; then
      dbug "Trying azcopy for $sas_token_url"
      # Replace with this stochastic version to test with failures.	
      # $thisdir/../prt/flaky 5 2 "$thisdir/stochastic_azcopy" 5 "$sas_token_url" "${CP_ROOT}/${TASK_ID}" && break
      $thisdir/../prt/flaky 5 4 azcopy copy "$sas_token_url" "${CP_ROOT}/${TASK_ID}" && break
    fi

    # Fallback to curl
    dbug "Trying curl for $sas_token_url"
    if [[ "$sas_token_url" == *"localhost"* ]]; then
      local_comp_port=$((CIRCA_BASEPORT + 501))
      local_comp_file_url=$(echo "$sas_token_url" | sed -E "s|localhost:[0-9]+|10.0.2.2:$local_comp_port|")
    else
      local_comp_file_url="$sas_token_url"
    fi

    dbug "local_comp_file_url is $local_comp_file_url"
    local_comp_filename="output_$(date +%s%N)"

    # Replace with this stochastic version to test with failures.
    # $thisdir/../prt/flaky 5 2 "$thisdir/stochastic_curl" 5 "$local_comp_file_url" "${CP_ROOT}/${TASK_ID}/$local_comp_filename" && break
    $thisdir/../prt/flaky 5 4 curl -o "${CP_ROOT}/${TASK_ID}/$local_comp_filename" -L "$local_comp_file_url" && break

    echo "Download failed. Retrying in $sleep_time seconds..."
    sleep $sleep_time
    sleep_time=$(( sleep_time * 2 > max_sleep ? max_sleep : sleep_time * 2 ))
  done
done

warn "Extracting archives and removing .tar.gz relics"
# find ${CP_ROOT}/${TASK_ID} -name "*.tar.gz" -execdir tar -xzvf {} \; -delete
for task_file in ${CP_ROOT}/${TASK_ID}/*; do
  if tar -tf "$task_file" > /dev/null 2>&1; then
    tar -xf "$task_file" -C ${CP_ROOT}/${TASK_ID}/
    warn "extracted: $task_file to ${CP_ROOT}/${TASK_ID}"
  else
    warn "skipping $task_file not an archive."
  fi
done

chown -R $CRS_API_USER ${CP_ROOT}/${TASK_ID}

# Done marker
touch "${CP_ROOT}/${TASK_ID}-DONE"

# hack to defeat make up from trying to download over this
touch ${CP_ROOT}/.pulled_mock-cp
touch ${CP_ROOT}/.pulled_nginx
exit 0
